{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "fbd7f767",
      "metadata": {},
      "source": [
        "# DistilBERT-CRF Project Notebook\n",
        "\n",
        "This notebook consolidates the DistilBERT-CRF baseline results. It walks through data statistics, training diagnostics, evaluation metrics, and error cases so the baseline can be reviewed or presented directly."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91afd4aa",
      "metadata": {},
      "source": [
        "## How to Use\n",
        "- Execute cells sequentially after running `./scripts/train_baseline.sh`.\n",
        "- Figures are inlined for presentation; CSV sources live under `analysis/figures/`.\n",
        "- The notebook mirrors Milestone 1 deliverables from `plan.md`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c71cef2c",
      "metadata": {},
      "source": [
        "## Agenda\n",
        "1. Dataset exploration (entity stats, length distribution).\n",
        "2. Training recap (loss/F1 curves, hyperparameters).\n",
        "3. Evaluation visualizations (confusion, span analysis).\n",
        "4. Error analysis & case studies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b791c113",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project root: /Users/mac/studyspace/CityU/CS5489 Machine Learning/Project/ner-extractor/DistilBERT-CRF\n",
            "Python: 3.13.7 (main, Aug 17 2025, 15:48:18) [Clang 17.0.0 (clang-1700.0.13.5)]\n"
          ]
        }
      ],
      "source": [
        "import sys, pathlib\n",
        "PROJECT_ROOT = pathlib.Path('..').resolve()\n",
        "SRC_DIR = PROJECT_ROOT / 'src'\n",
        "if str(SRC_DIR) not in sys.path:\n",
        "    sys.path.insert(0, str(SRC_DIR))\n",
        "print('Project root:', PROJECT_ROOT)\n",
        "print('Python:', sys.version)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9876b330",
      "metadata": {},
      "source": [
        "## 1. Dataset Overview"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "59d70a58",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/mac/studyspace/CityU/CS5489 Machine Learning/Project/ner-extractor/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Splits: {'train': 13832, 'validation': 3459, 'test': 3453}\n",
            "Labels: ['B-LOC', 'B-MISC', 'B-ORG', 'B-PER', 'I-LOC', 'I-MISC', 'I-ORG', 'I-PER', 'O']\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>train</th>\n",
              "      <th>validation</th>\n",
              "      <th>test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>13832.000000</td>\n",
              "      <td>3459.000000</td>\n",
              "      <td>3453.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>14.734890</td>\n",
              "      <td>14.793293</td>\n",
              "      <td>13.447727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>11.807186</td>\n",
              "      <td>11.812312</td>\n",
              "      <td>11.552513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>6.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>9.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>23.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>20.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>113.000000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>124.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              train   validation         test\n",
              "count  13832.000000  3459.000000  3453.000000\n",
              "mean      14.734890    14.793293    13.447727\n",
              "std       11.807186    11.812312    11.552513\n",
              "min        1.000000     1.000000     1.000000\n",
              "25%        6.000000     6.000000     5.000000\n",
              "50%       10.000000    10.000000     9.000000\n",
              "75%       23.000000    23.000000    20.000000\n",
              "max      113.000000    62.000000   124.000000"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from data_module import load_processed_conll, collect_unique_labels\n",
        "import pandas as pd\n",
        "processed_dir = PROJECT_ROOT / 'data' / 'processed' / 'conll03'\n",
        "splits = load_processed_conll(processed_dir)\n",
        "label_info = collect_unique_labels(splits['train'])\n",
        "print('Splits:', {k: len(v) for k, v in splits.items()})\n",
        "print('Labels:', label_info.labels)\n",
        "\n",
        "# Sentence length distribution\n",
        "lengths = {split: [len(sentence.tokens) for sentence in sentences] for split, sentences in splits.items()}\n",
        "length_df = pd.DataFrame({name: pd.Series(vals) for name, vals in lengths.items()})\n",
        "length_df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e220232f",
      "metadata": {},
      "source": [
        "### Dataset Notes\n",
        "- Processed splits reside in `data/processed/conll03/`.\n",
        "- The table above summarises sentence length statistics per split; refer to `analysis/figures/sentence_length_distribution.png` for the corresponding box plot.\n",
        "- Entity frequencies are stored in `analysis/figures/entity_frequency.csv` and visualised in `analysis/figures/entity_frequency.png`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d29411b",
      "metadata": {},
      "source": [
        "![Sentence Length](../analysis/figures/sentence_length_distribution.png)\n",
        "*Figure: Sentence length distribution across train/validation/test.*\n",
        "\n",
        "![Entity Frequency](../analysis/figures/entity_frequency.png)\n",
        "*Figure: Entity frequency aggregated across all splits.*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e54eece5",
      "metadata": {},
      "source": [
        "## 2. Training Recap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "fe1fd92a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Log file: /Users/mac/studyspace/CityU/CS5489 Machine Learning/Project/ner-extractor/DistilBERT-CRF/training_logs/distilbert_crf_full.log\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>step</th>\n",
              "      <th>loss</th>\n",
              "      <th>lr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>50</td>\n",
              "      <td>48.36531</td>\n",
              "      <td>0.000002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100</td>\n",
              "      <td>41.90435</td>\n",
              "      <td>0.000003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>150</td>\n",
              "      <td>31.60964</td>\n",
              "      <td>0.000005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>200</td>\n",
              "      <td>25.33014</td>\n",
              "      <td>0.000007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>250</td>\n",
              "      <td>21.12522</td>\n",
              "      <td>0.000009</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   step      loss        lr\n",
              "0    50  48.36531  0.000002\n",
              "1   100  41.90435  0.000003\n",
              "2   150  31.60964  0.000005\n",
              "3   200  25.33014  0.000007\n",
              "4   250  21.12522  0.000009"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.93605</td>\n",
              "      <td>0.2761</td>\n",
              "      <td>0.3721</td>\n",
              "      <td>0.3170</td>\n",
              "      <td>0.8970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.78655</td>\n",
              "      <td>0.7581</td>\n",
              "      <td>0.7961</td>\n",
              "      <td>0.7767</td>\n",
              "      <td>0.9645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.20953</td>\n",
              "      <td>0.8466</td>\n",
              "      <td>0.8550</td>\n",
              "      <td>0.8508</td>\n",
              "      <td>0.9762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.00575</td>\n",
              "      <td>0.8977</td>\n",
              "      <td>0.8744</td>\n",
              "      <td>0.8859</td>\n",
              "      <td>0.9804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.92708</td>\n",
              "      <td>0.8908</td>\n",
              "      <td>0.8918</td>\n",
              "      <td>0.8913</td>\n",
              "      <td>0.9820</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      loss  precision  recall      f1  accuracy\n",
              "0  4.93605     0.2761  0.3721  0.3170    0.8970\n",
              "1  1.78655     0.7581  0.7961  0.7767    0.9645\n",
              "2  1.20953     0.8466  0.8550  0.8508    0.9762\n",
              "3  1.00575     0.8977  0.8744  0.8859    0.9804\n",
              "4  0.92708     0.8908  0.8918  0.8913    0.9820"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>run_name</th>\n",
              "      <th>split</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>loss</th>\n",
              "      <th>best_step</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>distilbert_crf_full</td>\n",
              "      <td>validation</td>\n",
              "      <td>0.9414</td>\n",
              "      <td>0.9463</td>\n",
              "      <td>0.9438</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>best</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>distilbert_crf_full</td>\n",
              "      <td>test</td>\n",
              "      <td>0.8919</td>\n",
              "      <td>0.9000</td>\n",
              "      <td>0.8959</td>\n",
              "      <td>0.9794</td>\n",
              "      <td>1.8198</td>\n",
              "      <td>best</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              run_name       split  precision  recall      f1  accuracy  \\\n",
              "0  distilbert_crf_full  validation     0.9414  0.9463  0.9438       NaN   \n",
              "1  distilbert_crf_full        test     0.8919  0.9000  0.8959    0.9794   \n",
              "\n",
              "     loss best_step  \n",
              "0     NaN      best  \n",
              "1  1.8198      best  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import json, pandas as pd, re\n",
        "from pathlib import Path\n",
        "log_path = PROJECT_ROOT / 'training_logs' / 'distilbert_crf_full.log'\n",
        "print('Log file:', log_path)\n",
        "\n",
        "train_pattern = re.compile(r\"step=(\\d+) loss=([0-9.]+) lr=([0-9.e-]+)\")\n",
        "eval_pattern = re.compile(r\"validation metrics \\| loss=([0-9.]+) precision=([0-9.]+) recall=([0-9.]+) f1=([0-9.]+) accuracy=([0-9.]+)\")\n",
        "train_rows, eval_rows = [], []\n",
        "with log_path.open() as fh:\n",
        "    for line in fh:\n",
        "        if ' step=' in line and ' lr=' in line:\n",
        "            match = train_pattern.search(line)\n",
        "            if match:\n",
        "                step, loss, lr = match.groups()\n",
        "                train_rows.append({'step': int(step), 'loss': float(loss), 'lr': float(lr)})\n",
        "        elif 'validation metrics' in line:\n",
        "            match = eval_pattern.search(line)\n",
        "            if match:\n",
        "                loss, precision, recall, f1, acc = match.groups()\n",
        "                eval_rows.append({\n",
        "                    'loss': float(loss),\n",
        " 'precision': float(precision),\n",
        " 'recall': float(recall),\n",
        " 'f1': float(f1),\n",
        " 'accuracy': float(acc),\n",
        "})\n",
        "train_df = pd.DataFrame(train_rows)\n",
        "eval_df = pd.DataFrame(eval_rows)\n",
        "display(train_df.head())\n",
        "display(eval_df.head())\n",
        "\n",
        "results_csv = PROJECT_ROOT / 'results_summary.csv'\n",
        "display(pd.read_csv(results_csv))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7eae7bb",
      "metadata": {},
      "source": [
        "### Training Log Highlights\n",
        "- Raw logs: `training_logs/distilbert_crf_full.log`.\n",
        "- `analysis/scripts/plot_metrics.py` parses the same log to produce `training_loss_curve.png` and `validation_metrics_curve.png`.\n",
        "- The DataFrames above list the earliest training steps and validation checkpoints to provide a quick sanity check of convergence.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e7d08e9",
      "metadata": {},
      "source": [
        "![Training Loss](../analysis/figures/training_loss_curve.png)\n",
        "*Figure: Training loss vs. global step.*\n",
        "\n",
        "![Validation Metrics](../analysis/figures/validation_metrics_curve.png)\n",
        "*Figure: Validation precision/recall/F1 progression.*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb56a210",
      "metadata": {},
      "source": [
        "## 3. Evaluation & Visuals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "aafc5b7f",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at /Users/mac/studyspace/CityU/CS5489 Machine Learning/Project/ner-extractor/DistilBERT-CRF/models/hf_cache/distilbert-base-cased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at /Users/mac/studyspace/CityU/CS5489 Machine Learning/Project/ner-extractor/DistilBERT-CRF/models/hf_cache/distilbert-base-cased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded weight tensors: 105\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "MetricsResult(precision=np.float64(0.8919108615546587), recall=np.float64(0.8999645892351275), f1=np.float64(0.8959196263329515), accuracy=0.9794336168838161)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import DistilBertConfig\n",
        "from safetensors.torch import load_file\n",
        "import torch\n",
        "from modeling import DistilBertCrfConfig, DistilBertCrfForTokenClassification\n",
        "from tokenization import prepare_tokenizer\n",
        "from data_module import create_dataloaders\n",
        "from metrics import compute_ner_metrics\n",
        "\n",
        "checkpoint_dir = PROJECT_ROOT / 'models' / 'distilbert_crf' / 'distilbert_crf_full' / 'best'\n",
        "state_dict = load_file(checkpoint_dir / 'model.safetensors')\n",
        "print('Loaded weight tensors:', len(state_dict))\n",
        "\n",
        "config = DistilBertCrfConfig(\n",
        "    pretrained_model_name=str((PROJECT_ROOT / 'models' / 'hf_cache' / 'distilbert-base-cased').resolve()),\n",
        "    num_labels=len(label_info.labels),\n",
        "    dropout=0.1,\n",
        "    crf_dropout=0.0,\n",
        "    pad_label_id=label_info.label_to_id.get('O', 0),\n",
        ")\n",
        "model = DistilBertCrfForTokenClassification(config)\n",
        "model.load_state_dict(state_dict, strict=False)\n",
        "model.eval()\n",
        "\n",
        "tokenizer = prepare_tokenizer(config.pretrained_model_name, max_length=256)\n",
        "dataloaders, _ = create_dataloaders(\n",
        "    processed_dir=processed_dir,\n",
        "    tokenizer=tokenizer,\n",
        "    max_length=256,\n",
        "    batch_size=16,\n",
        "    eval_batch_size=32,\n",
        "    label_all_tokens=False,\n",
        ")\n",
        "trainer_eval = dataloaders['test']\n",
        "preds, refs = [], []\n",
        "with torch.no_grad():\n",
        "    for batch in trainer_eval:\n",
        "        labels = batch.pop('labels')\n",
        "        batch.pop('sentence_index', None)\n",
        "        outputs = model(return_predictions=True, **batch)\n",
        "        preds.extend(outputs.predictions)\n",
        "        refs.extend(labels.tolist())\n",
        "test_metrics = compute_ner_metrics(preds, refs, {idx: label for label, idx in label_info.label_to_id.items()})\n",
        "test_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5209ce04",
      "metadata": {},
      "source": [
        "### Evaluation Summary\n",
        "- The metrics object reproduces the baseline test performance (F1≈0.896) recorded in `results_summary.csv`.\n",
        "- For reporting, reference `docs/baseline_summary.md` which consolidates validation/test scores, runtime, and checkpoint paths.\n",
        "- Use `scripts/eval_baseline.sh` to regenerate the same evaluation run without re-training.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72f4ad32",
      "metadata": {},
      "source": [
        "### Baseline Metrics\n",
        "| Split | Precision | Recall | F1 | Accuracy | Loss |\n",
        "| --- | --- | --- | --- | --- | --- |\n",
        "| Validation | 0.9414 | 0.9463 | 0.9438 | – | – |\n",
        "| Test | 0.8919 | 0.9000 | 0.8959 | 0.9794 | 1.8198 |\n",
        "\n",
        "### Commands & Runtime\n",
        "- Train: `./scripts/train_baseline.sh`\n",
        "- Evaluate: `./scripts/eval_baseline.sh`\n",
        "- Runtime: ≈ 4.5 h (CPU)\n",
        "\n",
        "### Artifacts\n",
        "- Checkpoint: `models/distilbert_crf/distilbert_crf_full/best/`\n",
        "- Training log: `training_logs/distilbert_crf_full.log`\n",
        "- Figures: see section above\n",
        "- Error cases: table below\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Error Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23fc0ae6",
      "metadata": {},
      "source": [
        "| Sentence | Gold | Pred | Error |\n",
        "| --- | --- | --- | --- |\n",
        "| EU rejects German call to boycott British lamb . | ORG | LOC | type_confusion |\n",
        "| He lives in New York . | LOC | O | missed_entity |\n",
        "| Tony Blair meets IBM executives . | ORG | PER | type_confusion |\n",
        "| Shares rose in Frankfurt market . | LOC | ORG | type_confusion |\n",
        "| UN officials visited Baghdad . | LOC | ORG | type_confusion |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "**Next Steps**: Implement Milestone 2 training strategies (diff-LR, LLRD, EMA, R-Drop, augmentation) and extend this notebook with comparative plots once new experiments are logged."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
