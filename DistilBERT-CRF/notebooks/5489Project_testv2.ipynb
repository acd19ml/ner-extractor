{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBBsupwrm_Yy",
        "outputId": "0ccdda66-d162-485e-98ac-cb7ec4e52c4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# (Test Cell 1) 安装必要包并挂载 Drive\n",
        "!pip install -q pytorch-crf seqeval\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os, pickle, torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "SAVE_DIR = \"/content/drive/MyDrive/CRFmodel\"   # <-- 根据你的路径修改\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word2id = pickle.load(open(os.path.join(SAVE_DIR, \"word2id.pkl\"), \"rb\"))\n",
        "id2label = pickle.load(open(os.path.join(SAVE_DIR, \"id2label.pkl\"), \"rb\"))\n",
        "label2id = pickle.load(open(os.path.join(SAVE_DIR, \"label2id.pkl\"), \"rb\"))\n",
        "\n",
        "print(\"Vocab size:\", len(word2id))\n",
        "print(\"Num labels:\", len(id2label))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pf53xzpCe2GT",
        "outputId": "1c991d0a-eeb3-4585-e376-6232ceacbeef"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size: 21011\n",
            "Num labels: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "state = torch.load(os.path.join(SAVE_DIR, \"bilstm_crf_ner_model.pt\"), map_location=device)\n",
        "\n",
        "# infer emb_dim\n",
        "emb_dim = state['embedding.weight'].shape[1]\n",
        "\n",
        "# infer hidden_dim\n",
        "# CRF model: hidden2tag.weight shape = [tagset, hidden_dim*2]\n",
        "tagset, fc_in = state['hidden2tag.weight'].shape\n",
        "hidden_dim = fc_in // 2\n",
        "\n",
        "print(\"Inferred emb_dim =\", emb_dim)\n",
        "print(\"Inferred hidden_dim =\", hidden_dim)\n",
        "print(\"Tagset size =\", tagset)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2S90bF7JiVME",
        "outputId": "68a6666c-728c-48d9-e889-3ca518718c3d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inferred emb_dim = 100\n",
            "Inferred hidden_dim = 256\n",
            "Tagset size = 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BiLSTM_CRF(nn.Module):\n",
        "    def __init__(self, vocab_size, tagset_size, emb_dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(\n",
        "            emb_dim, hidden_dim,\n",
        "            bidirectional=True,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.hidden2tag = nn.Linear(hidden_dim * 2, tagset_size)\n",
        "        self.crf = CRF(tagset_size, batch_first=True)\n",
        "\n",
        "    def forward(self, x, tags=None, mask=None):\n",
        "        emb = self.embedding(x)\n",
        "        lstm_out, _ = self.lstm(emb)\n",
        "        emissions = self.hidden2tag(lstm_out)\n",
        "        if tags is not None:\n",
        "            return -self.crf(emissions, tags, mask=mask, reduction=\"mean\")\n",
        "        else:\n",
        "            return self.crf.decode(emissions, mask=mask)\n"
      ],
      "metadata": {
        "id": "-dBiCJxfe4f6"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BiLSTM_CRF(\n",
        "    vocab_size=len(word2id),\n",
        "    tagset_size=len(id2label),\n",
        "    emb_dim=emb_dim,\n",
        "    hidden_dim=hidden_dim\n",
        ").to(device)\n",
        "\n",
        "model.load_state_dict(state)\n",
        "model.eval()\n",
        "\n",
        "print(\"Model loaded successfully!\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tG7D1p3oe6V8",
        "outputId": "408b4c24-829b-40d8-fefe-cdbb881dad2f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 128\n",
        "\n",
        "def encode(tokens):\n",
        "    ids = [word2id.get(w.lower(), word2id.get(\"<UNK>\", 1)) for w in tokens]\n",
        "    ids = ids[:MAX_LEN]\n",
        "    mask = [1] * len(ids)\n",
        "    pad_len = MAX_LEN - len(ids)\n",
        "    ids += [0] * pad_len\n",
        "    mask += [0] * pad_len\n",
        "    return torch.tensor([ids], dtype=torch.long), torch.tensor([mask], dtype=torch.bool)\n"
      ],
      "metadata": {
        "id": "4ou2TblefLvM"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(tokens):\n",
        "    x, mask = encode(tokens)\n",
        "    x, mask = x.to(device), mask.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pred_ids = model(x, mask=mask)[0]\n",
        "\n",
        "    return [id2label[i] for i in pred_ids[:len(tokens)]]\n"
      ],
      "metadata": {
        "id": "kwudSFkrgSXX"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_entities(tokens, labels):\n",
        "    entities = []\n",
        "    cur = []\n",
        "    ent_type = None\n",
        "\n",
        "    for w, t in zip(tokens, labels):\n",
        "        if t.startswith(\"B-\"):\n",
        "            if cur:\n",
        "                entities.append((\" \".join(cur), ent_type))\n",
        "            cur = [w]\n",
        "            ent_type = t[2:]\n",
        "\n",
        "        elif t.startswith(\"I-\") and cur:\n",
        "            cur.append(w)\n",
        "\n",
        "        else:\n",
        "            if cur:\n",
        "                entities.append((\" \".join(cur), ent_type))\n",
        "            cur = []\n",
        "            ent_type = None\n",
        "\n",
        "    if cur:\n",
        "        entities.append((\" \".join(cur), ent_type))\n",
        "\n",
        "    return entities\n"
      ],
      "metadata": {
        "id": "hYbSfophiizf"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"I study at City University of Hong Kong with John Smith .\"\n",
        "tokens = sentence.split()\n",
        "\n",
        "labels = predict(tokens)\n",
        "entities = extract_entities(tokens, labels)\n",
        "\n",
        "print(\"Tokens:\", tokens)\n",
        "print(\"Labels:\", labels)\n",
        "print(\"Entities:\", entities)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjae4lDmilDJ",
        "outputId": "a1e9501b-c203-41df-fcb6-600ce8641c40"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['I', 'study', 'at', 'City', 'University', 'of', 'Hong', 'Kong', 'with', 'John', 'Smith', '.']\n",
            "Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'B-PER', 'I-PER', 'O']\n",
            "Entities: [('Hong Kong', 'LOC'), ('John Smith', 'PER')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"I studied at the University of Cambridge .\"\n",
        "tokens = sentence.split()\n",
        "\n",
        "labels = predict(tokens)\n",
        "entities = extract_entities(tokens, labels)\n",
        "\n",
        "print(\"Sentence:\", \" \".join(tokens))\n",
        "print(\"Labels:  \", labels)\n",
        "print(\"Entities:\", entities)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6LkSuJwjJBM",
        "outputId": "780d2a10-ef85-4270-bbde-ade42da15eff"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: I studied at the University of Cambridge .\n",
            "Labels:   ['O', 'O', 'O', 'O', 'B-ORG', 'O', 'B-LOC', 'O']\n",
            "Entities: [('University', 'ORG'), ('Cambridge', 'LOC')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"He graduated from Oxford University last year .\"\n",
        "tokens = sentence.split()\n",
        "\n",
        "labels = predict(tokens)\n",
        "entities = extract_entities(tokens, labels)\n",
        "\n",
        "print(\"Sentence:\", \" \".join(tokens))\n",
        "print(\"Labels:  \", labels)\n",
        "print(\"Entities:\", entities)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oz51KDoijMFe",
        "outputId": "557a0def-cbc5-4a63-949a-9604e3654765"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: He graduated from Oxford University last year .\n",
            "Labels:   ['O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O']\n",
            "Entities: [('Oxford University', 'ORG')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"She visited Tsinghua University in Beijing .\"\n",
        "tokens = sentence.split()\n",
        "\n",
        "labels = predict(tokens)\n",
        "entities = extract_entities(tokens, labels)\n",
        "\n",
        "print(\"Sentence:\", \" \".join(tokens))\n",
        "print(\"Labels:  \", labels)\n",
        "print(\"Entities:\", entities)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pC--EH3BjOpF",
        "outputId": "c0fef8ec-3f4f-4a54-ee13-5c25152c5162"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: She visited Tsinghua University in Beijing .\n",
            "Labels:   ['O', 'O', 'B-ORG', 'I-ORG', 'O', 'B-LOC', 'O']\n",
            "Entities: [('Tsinghua University', 'ORG'), ('Beijing', 'LOC')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "不是哥们，清华都能识别出来，你城就不行吗"
      ],
      "metadata": {
        "id": "iiLl0Pqbja_W"
      }
    }
  ]
}